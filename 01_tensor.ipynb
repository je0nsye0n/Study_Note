{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [01. 텐서]\n",
    "* 텐서(tensor) : 넘파이 라이브러리의 ndarray 클래스와 유사한 구조로 배열이나 행렬과 유사한 자료 구조\n",
    "- 파이토치에서는 텐서를 사용하여 모델의 입출력 뿐만 아니라 모델의 매개변수를 부호화(Encode)하고, GPU를 활용해 연산을 가속화할 수 있다.\n",
    "\n",
    "- 넘파이와 파이토치의 공통점 : 수학 계산, 선형 대수를 비롯한 전치, 인덱싱, 슬라이싱 등 다양한 텐서 연산 가능\n",
    "- 넘파이와 파이토치의 차이점 : CPU에서 사용하는 텐서와 GPU에서 사용하는 텐서의 선언 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 텐서 생성\n",
    "- 텐서 생성 방법 \n",
    "1. torch.tensor() // 소문자 - 입력된 데이터를 복사해 텐서로 변환하는 함수\n",
    "2. torch.Tensor() // 대문자 - 텐서의 기본형으로 텐서 인스턴스를 생성하는 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.tensor([1,2,3])) #자동으로 자료형 할당 - int형\n",
    "print(torch.Tensor(([1,2,3],[4,5,6]))) #입력형식이 Int지만 Float로 생성된 것을 확인할 수 있음\n",
    "print(torch.LongTensor([1,2,3]))\n",
    "print(torch.FloatTensor([1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***   \n",
    "* 텐서의 속성 : 형태(shape/텐서의 차원), 자료형(dtype/데이터 형식), 장치(device/GPU 가속 여부)\n",
    "\n",
    "* 장치 설정 : 텐서의 장치 설정은 GPU 학습에서 가장 중요한 설정이다. 정확하게 할당하지 않으면 실행 오류가 발생하거나 CPU 연산이 되어 학습하는데 오래 걸리게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2276, 0.4154]])\n",
      "torch.Size([1, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#텐서 속성(3.2)\n",
    "\n",
    "tensor = torch.rand(1,2) #0과 1사이 무작위 숫자를 균등 분포로 생성하는 함수\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7591, 0.2249]])\n",
      "torch.Size([1, 2])\n",
      "tensor([[0.7591],\n",
      "        [0.2249]])\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "#차원 변환(3.3)\n",
    "tensor = torch.rand(1,2)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "\n",
    "tensor=tensor.reshape(2,1)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3293, 0.3256, 0.1775],\n",
      "        [0.7137, 0.0611, 0.3999],\n",
      "        [0.9903, 0.0555, 0.3058]])\n"
     ]
    }
   ],
   "source": [
    "#자료형 설정(3.4)\n",
    "\n",
    "tensor = torch.rand((3,3), dtype=torch.float)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SDLPC187\\AppData\\Local\\Temp\\ipykernel_9988\\4203497411.py:3: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:80.)\n",
      "  gpu = torch.cuda.FloatTensor([1,2,3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda tensor([1., 2., 3.]) tensor([1., 2., 3.], device='cuda:0') tensor([[0.2843]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#장치 설정(3.5)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cpu = torch.FloatTensor([1,2,3])\n",
    "gpu = torch.cuda.FloatTensor([1,2,3])\n",
    "tensor = torch.rand((1,1), device=device)\n",
    "print(device, cpu, gpu, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#장치 변환(3.6)\n",
    "\n",
    "cpu = torch.FloatTensor([1,2,3])\n",
    "gpu = cpu.cuda()\n",
    "gpu2cpu = gpu.cpu()\n",
    "cpu2gpu = cpu.to(\"cuda\")\n",
    "print(gpu2cpu)\n",
    "print(cpu2gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- 넘파이 배열의 텐서 변환    \n",
    "넘파이 배열을 텐서로 변환하는 방법은 크게 세 가지가 있다 -> torch.tensor / torch.Tensor에 넘파이 배열을 그대로 입력 / from_numpy 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.uint8)\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.uint8)\n",
      "[1. 2. 3.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#넘파이 배열의 텐서 변환(3.7)\n",
    "import numpy as np\n",
    "ndarray = np.array([1,2,3], dtype=np.uint8)\n",
    "print(torch.tensor(ndarray))\n",
    "print(torch.Tensor(ndarray))\n",
    "print(torch.from_numpy(ndarray))\n",
    "\n",
    "#텐서의 넘파이 배열 변환(3.8)\n",
    "tensor = torch.cuda.FloatTensor([1,2,3])\n",
    "ndarray=tensor.detach().cpu().numpy()\n",
    "print(ndarray)\n",
    "print(type(ndarray))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
